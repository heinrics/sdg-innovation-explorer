import sys
import xml.etree.ElementTree as ET
import re
import pandas as pd
from collections import defaultdict

# SET environment ##############################################################
################################################################################

# Computer currently running on
WORK_ENV = sys.platform # linux | darwin
EXT_DRIVE = 'tb4m2' # tb4m2, T5 EVO

# Directory paths
if WORK_ENV == 'darwin':
    PROJ_DIR = '/Users/sebastianheinrich/Dropbox/EPO-Code-FEST-SDG'
    EXT_DRIVE = '/Volumes/' + EXT_DRIVE

elif WORK_ENV == 'linux':
    PROJ_DIR = '/mnt/7adaf322-ecbb-4b5d-bc6f-4c54f7f808eb/Dropbox/EPO-Code-FEST-SDG/'
    EXT_DRIVE = '/media/heinrics/' + EXT_DRIVE

# Pandas display options
pd.set_option('display.max_columns', 100)
pd.set_option('display.width', 2000)
pd.set_option('display.max_colwidth', None)

# EXTRACT SDG queries from XML #################################################
################################################################################

# Namespace map of SDG query xml
ns = {
    'aqd': 'http://aurora-network.global/queries/namespace/',
    'dc': 'http://dublincore.org/documents/dcmi-namespace/'
}

def transform_query(query_line):

    # Extract raw text and strip leading and trailing spaces
    raw_text = query_line.text.strip()

    # Transform to query for manticore search
    query_text = (raw_text.replace('\n', ' ')
                  .replace('AND', ' ')
                  .replace('OR', '|')
                  .replace('W/1', 'NEAR/1')
                  .replace('W/2', 'NEAR/2')
                  .replace('W/3', 'NEAR/3')
                  .replace('W/6', 'NEAR/6')
                  .replace('"', '')
                  .replace('( ', '(')
                  .replace(' )', ')'))
    # Remove multiple white spaces
    query_text = re.sub(r'\s+', ' ', query_text).strip()

    # query_text = '(' + query_text + ')'

    return query_text


def parse_scopus_xml(xml_string, sdg_goal):

    # Get XML root
    root = ET.fromstring(xml_string)

    # List to capture extracted queries
    extracted_queries = []

    # Iterate over all query definitions
    for query_def in root.findall('.//aqd:query-definition', ns):
        # Extract SDG section
        identifier = query_def.find('dc:identifier', ns)
        subquery_id = query_def.find('aqd:subquery-identifier', ns)
        sdg_code = identifier.text.split('/')[-1] if identifier is not None else subquery_id.text

        # Find all queries per section
        query_lines = query_def.findall('.//aqd:query-line', ns)

        # Transform each query into the manticore search syntax
        for query_line in query_lines:
            if query_line.text:
                # Transform text
                query_text = transform_query(query_line)
                # Collect transformation results and SDG info in list
                extracted_queries.append([sdg_goal, sdg_code, query_text])
            else:
                continue

    return extracted_queries


# Iterate over all SDG goals (1 xml file per goal) #############################

# Collect queries for all goals
query_list = []

for sdg_goal in range(1, 17+1):
    print(sdg_goal)

    # File path to original xml file
    # Manually downloaded from https://aurora-network-global.github.io/sdg-queries/
    path = f'{PROJ_DIR}/Data/sdg-queries/query_SDG{sdg_goal}.xml'

    # Read XML file
    with open(path, 'r', encoding='utf-8') as f:
        xml_content = f.read()

    # Parse xml, extract and transform queries
    test = parse_scopus_xml(xml_content, str(sdg_goal))
    # Collect queries in a list
    query_list.extend(test)

# Create pandas dataframe from the list of lists
query_df = pd.DataFrame(query_list, columns=['goal', 'section', 'text'])


# The wrap_terms function was generated by chatgpt.
# The goal is to wrap the OR statements so the default 'AND' of manticore search
# is not altering the meaning of the queries

# Prompt:
# I need to do string transformations in python. Here are a few examples:
#
# (poverty) NEAR/3 (living | life | child* | socioeconomic* | socio-economic* | social welfare | household* | income*) | (poverty line*)
# Needs to be transformed into:
# (poverty) NEAR/3 ((living) | (life) | (child*) | (socioeconomic*) | (socio-economic*) | (social welfare) | (household*) | (income*)) | (poverty line*)
#
# population census | housing census | birth registration* | death registration*
# Needs to be transformed into:
# (population census) | (housing census) | (birth registration*) | (death registration*)
#
# (SDG* | sustainable development*) NEAR/3 (progress* | measurement* | measuring | monitor*)
# Needs to be transformed into:
# ((SDG*) | (sustainable development*)) NEAR/3 ((progress*) | (measurement*) | (measuring) | (monitor*))
#
# What is an elegant python solution for this problem?


def wrap_terms(expression: str) -> str:
    # Wrap individual terms in parentheses if not already
    def wrap_in_parens(group_str):
        terms = [t.strip() for t in group_str.split('|')]
        wrapped_terms = [f'({t})' if not re.match(r'^\(.*\)$', t) else t for t in terms]
        return ' | '.join(wrapped_terms)

    # Process alternations inside parentheses
    def process_sub_expr(expr):
        def replacer(match):
            inner = match.group(1)
            return f"({wrap_in_parens(inner)})"
        return re.sub(r'\(([^()]*\|[^()]*)\)', replacer, expr)

    # Process top-level alternations not in parentheses
    def process_top_level(expr):
        parts = []
        depth = 0
        current = ''
        for char in expr:
            if char == '(':
                depth += 1
            elif char == ')':
                depth -= 1
            if char == '|' and depth == 0:
                parts.append(current.strip())
                current = ''
            else:
                current += char
        parts.append(current.strip())
        # Wrap top-level terms not already parenthesized
        parts = [f'({p})' if not re.match(r'^\(.*\)$', p) else p for p in parts]
        return ' | '.join(parts)

    expression = process_sub_expr(expression)
    return process_top_level(expression)


query_df['text'] = query_df['text'].apply(lambda x: wrap_terms(x))


# Serialize pandas dataframe to parquet
query_df.to_parquet(f'{PROJ_DIR}/Data/sdg-queries/manticore-queries.parquet')
